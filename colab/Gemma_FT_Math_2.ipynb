{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA0pwrfgaijE"
      },
      "outputs": [],
      "source": [
        "# ÏÑ∏ÏÖò Ïú†ÏßÄ ÏΩîÎìú\n",
        "from IPython.display import clear_output\n",
        "import threading, time\n",
        "\n",
        "def keep_alive():\n",
        "    for i in range(100000):\n",
        "        time.sleep(60)\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Ping {i} ‚è±Ô∏è\")\n",
        "\n",
        "threading.Thread(target=keep_alive).start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mgzv-Tobz4l"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sbZey_kaUqM"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 0. Install & Import Dependencies\n",
        "# ==========================================\n",
        "!pip install transformers datasets peft accelerate bitsandbytes --quiet\n",
        "\n",
        "import torch\n",
        "from datasets import load_from_disk\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5Y-XMnqaaTy"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 1. Load Dataset (Math binary classification)\n",
        "# ==========================================\n",
        "print(\"üîÑ Loading dataset...\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset = load_from_disk(\"/content/drive/MyDrive/Gemma_FineTuning/math_eval_binary_dataset\")\n",
        "\n",
        "# Optional: ÌôïÏù∏\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsWEoczFabtj"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 2. Load Model & Tokenizer\n",
        "# ==========================================\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=\"YOUR_HF_TOKEN\")\n",
        "\n",
        "model_id = \"google/gemma-3n-E2B-it\"  # Use the same model used during generation\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quant_config,\n",
        "    num_labels=2,  # Binary classification (correct/incorrect)\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pi86aiHafWB"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. LoRA Config\n",
        "# ==========================================\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke_3lLFVagld"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 4. Dataset Preprocessing (Ìè¨Îß∑ ÏÑ§Ï†ï)\n",
        "# ==========================================\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37J8CLw6aipO"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 5. TrainingArguments & Trainer\n",
        "# ==========================================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gemma3n-math-binary\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=25,\n",
        "    save_steps=250,\n",
        "    learning_rate=2e-4,\n",
        "    max_grad_norm=0.3,\n",
        "    warmup_ratio=0.03,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    report_to=None,\n",
        "    bf16=True,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    peft_config=lora_config,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXezo-LDak85"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 6. Start Training\n",
        "# ==========================================\n",
        "print(\"üöÄ Starting training...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jugHP_-QaPAx"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 7. Save to Drive & Hugging Face\n",
        "# ==========================================\n",
        "save_path = \"/content/drive/MyDrive/math_eval_binary\"\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "# Push to Hugging Face\n",
        "repo_id = \"LeannaJ/math_evaluation\"\n",
        "model.push_to_hub(repo_id)\n",
        "tokenizer.push_to_hub(repo_id)\n",
        "print(f\"‚úÖ Model pushed to Hugging Face: https://huggingface.co/{repo_id}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
